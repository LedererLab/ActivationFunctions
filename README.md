# Activation Functions in Artificial Neural Networks

This repository contains visualizations and corresponding `R` code for the paper 
 _Activation Functions in Artificial Neural Networks: A Systematic Overview._
 
### About the paper
Activation functions shape the outputs of artificial neurons and, therefore, are integral parts of neural networks in general and deep learning in particular. Some activation functions, such as logistic and relu, have been used for many decades. But with deep learning becoming a mainstream research topic, new activation functions have mushroomed, leading to confusion in both theory and practice. This paper provides an analytic yet up-to-date overview of popular activation functions and their properties, which makes it a timely resource for anyone who studies or applies neural networks.

**Keywords:** neural network; deep learning; activation function; transfer function.
 
### Repository author

* [Johannes Lederer](https://johanneslederer.com), _Ruhr-University Bochum_

### Citation

* Lederer, J. "Activation Functions in Artificial Neural Networks: A Systematic Overview." _arXiv_ (2021).
